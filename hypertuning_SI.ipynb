{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2dc6c-a4c3-4858-8746-10fd762da60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:28.327465Z",
     "iopub.status.busy": "2024-11-21T14:39:28.326967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt -q\n",
    "# !pip install ipython-autotime -q\n",
    "# !pip install optuna -q \n",
    "# !pip install plotly -q\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f4333d-89b9-4595-af27-fe9811842cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:17.233893Z",
     "iopub.status.busy": "2024-11-21T14:39:17.232595Z",
     "iopub.status.idle": "2024-11-21T14:39:23.357566Z",
     "shell.execute_reply": "2024-11-21T14:39:23.356116Z",
     "shell.execute_reply.started": "2024-11-21T14:39:17.233838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 14:39:18.532892: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-21 14:39:18.533022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-21 14:39:18.535262: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-21 14:39:18.549176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-21 14:39:20.241103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.15.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.6 ms (started: 2024-11-21 14:39:23 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 14:39:23.294284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-21 14:39:23.345569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-21 14:39:23.346139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Reshape, Flatten, Bidirectional, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autotime\n",
    "\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a131d3ef-8a5d-4d18-b97b-1636caf46390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:23.360792Z",
     "iopub.status.busy": "2024-11-21T14:39:23.360006Z",
     "iopub.status.idle": "2024-11-21T14:39:23.368096Z",
     "shell.execute_reply": "2024-11-21T14:39:23.366318Z",
     "shell.execute_reply.started": "2024-11-21T14:39:23.360745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 753 µs (started: 2024-11-21 14:39:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# parameter\n",
    "# n_steps_in: Number of input time steps\n",
    "# n_steps_out: Number of days to predict ahead\n",
    "\n",
    "n_steps_in = 14  \n",
    "n_steps_out = 5\n",
    "epochs = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f71067-767a-46a5-80a7-215a24bdabf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:23.370697Z",
     "iopub.status.busy": "2024-11-21T14:39:23.370272Z",
     "iopub.status.idle": "2024-11-21T14:39:23.540052Z",
     "shell.execute_reply": "2024-11-21T14:39:23.537765Z",
     "shell.execute_reply.started": "2024-11-21T14:39:23.370663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>WR</th>\n",
       "      <th>SMA7</th>\n",
       "      <th>SMA14</th>\n",
       "      <th>...</th>\n",
       "      <th>EMA7</th>\n",
       "      <th>EMA25</th>\n",
       "      <th>EMA99</th>\n",
       "      <th>EMA200</th>\n",
       "      <th>MACD</th>\n",
       "      <th>CCI</th>\n",
       "      <th>Upper Band</th>\n",
       "      <th>Lower Band</th>\n",
       "      <th>Ulcer Index</th>\n",
       "      <th>Close Next Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-19 00:00:00+00:00</th>\n",
       "      <td>25.937435</td>\n",
       "      <td>28.752501</td>\n",
       "      <td>29.129999</td>\n",
       "      <td>28.670000</td>\n",
       "      <td>29.025000</td>\n",
       "      <td>193146000</td>\n",
       "      <td>38.868505</td>\n",
       "      <td>-58.647164</td>\n",
       "      <td>28.875357</td>\n",
       "      <td>29.083214</td>\n",
       "      <td>...</td>\n",
       "      <td>29.011843</td>\n",
       "      <td>29.811806</td>\n",
       "      <td>30.819353</td>\n",
       "      <td>30.361521</td>\n",
       "      <td>-0.639367</td>\n",
       "      <td>-59.662038</td>\n",
       "      <td>30.115768</td>\n",
       "      <td>28.050661</td>\n",
       "      <td>8.949397</td>\n",
       "      <td>28.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-20 00:00:00+00:00</th>\n",
       "      <td>25.405201</td>\n",
       "      <td>28.162500</td>\n",
       "      <td>28.587500</td>\n",
       "      <td>27.907499</td>\n",
       "      <td>28.520000</td>\n",
       "      <td>274006400</td>\n",
       "      <td>34.842467</td>\n",
       "      <td>-76.661486</td>\n",
       "      <td>28.845357</td>\n",
       "      <td>28.928750</td>\n",
       "      <td>...</td>\n",
       "      <td>28.799508</td>\n",
       "      <td>29.684936</td>\n",
       "      <td>30.766216</td>\n",
       "      <td>30.339640</td>\n",
       "      <td>-0.675706</td>\n",
       "      <td>-101.719165</td>\n",
       "      <td>29.807586</td>\n",
       "      <td>28.049914</td>\n",
       "      <td>8.822285</td>\n",
       "      <td>26.440001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-21 00:00:00+00:00</th>\n",
       "      <td>23.851353</td>\n",
       "      <td>26.440001</td>\n",
       "      <td>27.975000</td>\n",
       "      <td>26.412500</td>\n",
       "      <td>27.607500</td>\n",
       "      <td>513102000</td>\n",
       "      <td>26.282999</td>\n",
       "      <td>-99.232910</td>\n",
       "      <td>28.506786</td>\n",
       "      <td>28.702321</td>\n",
       "      <td>...</td>\n",
       "      <td>28.209631</td>\n",
       "      <td>29.435326</td>\n",
       "      <td>30.679692</td>\n",
       "      <td>30.300837</td>\n",
       "      <td>-0.833884</td>\n",
       "      <td>-193.641185</td>\n",
       "      <td>30.187027</td>\n",
       "      <td>27.217616</td>\n",
       "      <td>8.940749</td>\n",
       "      <td>25.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-24 00:00:00+00:00</th>\n",
       "      <td>23.255964</td>\n",
       "      <td>25.780001</td>\n",
       "      <td>27.200001</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.717501</td>\n",
       "      <td>648825200</td>\n",
       "      <td>23.863926</td>\n",
       "      <td>-60.271513</td>\n",
       "      <td>28.077143</td>\n",
       "      <td>28.496607</td>\n",
       "      <td>...</td>\n",
       "      <td>27.602223</td>\n",
       "      <td>29.154147</td>\n",
       "      <td>30.581698</td>\n",
       "      <td>30.255854</td>\n",
       "      <td>-1.000959</td>\n",
       "      <td>-286.791374</td>\n",
       "      <td>30.611922</td>\n",
       "      <td>26.381293</td>\n",
       "      <td>9.012688</td>\n",
       "      <td>25.934999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-25 00:00:00+00:00</th>\n",
       "      <td>23.395788</td>\n",
       "      <td>25.934999</td>\n",
       "      <td>27.777500</td>\n",
       "      <td>25.875000</td>\n",
       "      <td>27.777500</td>\n",
       "      <td>414406400</td>\n",
       "      <td>25.595895</td>\n",
       "      <td>-58.056453</td>\n",
       "      <td>27.640715</td>\n",
       "      <td>28.288393</td>\n",
       "      <td>...</td>\n",
       "      <td>27.185417</td>\n",
       "      <td>28.906520</td>\n",
       "      <td>30.488764</td>\n",
       "      <td>30.212860</td>\n",
       "      <td>-1.108087</td>\n",
       "      <td>-175.033141</td>\n",
       "      <td>30.766350</td>\n",
       "      <td>25.810436</td>\n",
       "      <td>9.087065</td>\n",
       "      <td>27.422501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-25 00:00:00+00:00</th>\n",
       "      <td>231.155685</td>\n",
       "      <td>231.410004</td>\n",
       "      <td>233.220001</td>\n",
       "      <td>229.570007</td>\n",
       "      <td>229.740005</td>\n",
       "      <td>38802300</td>\n",
       "      <td>53.621399</td>\n",
       "      <td>-42.696626</td>\n",
       "      <td>233.175714</td>\n",
       "      <td>231.504286</td>\n",
       "      <td>...</td>\n",
       "      <td>232.117849</td>\n",
       "      <td>229.678046</td>\n",
       "      <td>219.220789</td>\n",
       "      <td>207.361942</td>\n",
       "      <td>2.040117</td>\n",
       "      <td>34.671127</td>\n",
       "      <td>237.405189</td>\n",
       "      <td>225.603382</td>\n",
       "      <td>1.664750</td>\n",
       "      <td>233.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-28 00:00:00+00:00</th>\n",
       "      <td>233.143494</td>\n",
       "      <td>233.399994</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>232.550003</td>\n",
       "      <td>233.320007</td>\n",
       "      <td>36087100</td>\n",
       "      <td>56.742652</td>\n",
       "      <td>-32.306559</td>\n",
       "      <td>233.354285</td>\n",
       "      <td>232.049285</td>\n",
       "      <td>...</td>\n",
       "      <td>232.438385</td>\n",
       "      <td>229.964350</td>\n",
       "      <td>219.504373</td>\n",
       "      <td>207.621027</td>\n",
       "      <td>2.033819</td>\n",
       "      <td>76.852796</td>\n",
       "      <td>237.075664</td>\n",
       "      <td>227.022906</td>\n",
       "      <td>1.484857</td>\n",
       "      <td>233.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-29 00:00:00+00:00</th>\n",
       "      <td>233.413193</td>\n",
       "      <td>233.669998</td>\n",
       "      <td>234.330002</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>233.100006</td>\n",
       "      <td>35417200</td>\n",
       "      <td>57.163889</td>\n",
       "      <td>-37.015549</td>\n",
       "      <td>233.164285</td>\n",
       "      <td>232.344285</td>\n",
       "      <td>...</td>\n",
       "      <td>232.746288</td>\n",
       "      <td>230.249399</td>\n",
       "      <td>219.787685</td>\n",
       "      <td>207.880220</td>\n",
       "      <td>2.027246</td>\n",
       "      <td>67.831787</td>\n",
       "      <td>237.229760</td>\n",
       "      <td>227.458811</td>\n",
       "      <td>1.465655</td>\n",
       "      <td>230.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30 00:00:00+00:00</th>\n",
       "      <td>229.847122</td>\n",
       "      <td>230.100006</td>\n",
       "      <td>233.470001</td>\n",
       "      <td>229.550003</td>\n",
       "      <td>232.610001</td>\n",
       "      <td>47070900</td>\n",
       "      <td>50.202829</td>\n",
       "      <td>-72.807810</td>\n",
       "      <td>232.252858</td>\n",
       "      <td>232.420000</td>\n",
       "      <td>...</td>\n",
       "      <td>232.084718</td>\n",
       "      <td>230.237908</td>\n",
       "      <td>219.993932</td>\n",
       "      <td>208.101313</td>\n",
       "      <td>1.714208</td>\n",
       "      <td>13.082281</td>\n",
       "      <td>237.127918</td>\n",
       "      <td>227.712083</td>\n",
       "      <td>1.568988</td>\n",
       "      <td>225.910004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 00:00:00+00:00</th>\n",
       "      <td>225.661728</td>\n",
       "      <td>225.910004</td>\n",
       "      <td>229.830002</td>\n",
       "      <td>225.369995</td>\n",
       "      <td>229.339996</td>\n",
       "      <td>64370100</td>\n",
       "      <td>43.506465</td>\n",
       "      <td>-95.544488</td>\n",
       "      <td>230.831430</td>\n",
       "      <td>232.302858</td>\n",
       "      <td>...</td>\n",
       "      <td>230.541039</td>\n",
       "      <td>229.904992</td>\n",
       "      <td>220.112253</td>\n",
       "      <td>208.278514</td>\n",
       "      <td>1.115170</td>\n",
       "      <td>-82.148649</td>\n",
       "      <td>237.541362</td>\n",
       "      <td>227.064353</td>\n",
       "      <td>1.870281</td>\n",
       "      <td>225.910004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2317 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                       Adj Close       Close        High         Low  \\\n",
       "Ticker                           AAPL        AAPL        AAPL        AAPL   \n",
       "Date                                                                        \n",
       "2015-08-19 00:00:00+00:00   25.937435   28.752501   29.129999   28.670000   \n",
       "2015-08-20 00:00:00+00:00   25.405201   28.162500   28.587500   27.907499   \n",
       "2015-08-21 00:00:00+00:00   23.851353   26.440001   27.975000   26.412500   \n",
       "2015-08-24 00:00:00+00:00   23.255964   25.780001   27.200001   23.000000   \n",
       "2015-08-25 00:00:00+00:00   23.395788   25.934999   27.777500   25.875000   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-10-25 00:00:00+00:00  231.155685  231.410004  233.220001  229.570007   \n",
       "2024-10-28 00:00:00+00:00  233.143494  233.399994  234.729996  232.550003   \n",
       "2024-10-29 00:00:00+00:00  233.413193  233.669998  234.330002  232.320007   \n",
       "2024-10-30 00:00:00+00:00  229.847122  230.100006  233.470001  229.550003   \n",
       "2024-10-31 00:00:00+00:00  225.661728  225.910004  229.830002  225.369995   \n",
       "\n",
       "Price                            Open     Volume        RSI         WR  \\\n",
       "Ticker                           AAPL       AAPL                         \n",
       "Date                                                                     \n",
       "2015-08-19 00:00:00+00:00   29.025000  193146000  38.868505 -58.647164   \n",
       "2015-08-20 00:00:00+00:00   28.520000  274006400  34.842467 -76.661486   \n",
       "2015-08-21 00:00:00+00:00   27.607500  513102000  26.282999 -99.232910   \n",
       "2015-08-24 00:00:00+00:00   23.717501  648825200  23.863926 -60.271513   \n",
       "2015-08-25 00:00:00+00:00   27.777500  414406400  25.595895 -58.056453   \n",
       "...                               ...        ...        ...        ...   \n",
       "2024-10-25 00:00:00+00:00  229.740005   38802300  53.621399 -42.696626   \n",
       "2024-10-28 00:00:00+00:00  233.320007   36087100  56.742652 -32.306559   \n",
       "2024-10-29 00:00:00+00:00  233.100006   35417200  57.163889 -37.015549   \n",
       "2024-10-30 00:00:00+00:00  232.610001   47070900  50.202829 -72.807810   \n",
       "2024-10-31 00:00:00+00:00  229.339996   64370100  43.506465 -95.544488   \n",
       "\n",
       "Price                            SMA7       SMA14  ...        EMA7  \\\n",
       "Ticker                                             ...               \n",
       "Date                                               ...               \n",
       "2015-08-19 00:00:00+00:00   28.875357   29.083214  ...   29.011843   \n",
       "2015-08-20 00:00:00+00:00   28.845357   28.928750  ...   28.799508   \n",
       "2015-08-21 00:00:00+00:00   28.506786   28.702321  ...   28.209631   \n",
       "2015-08-24 00:00:00+00:00   28.077143   28.496607  ...   27.602223   \n",
       "2015-08-25 00:00:00+00:00   27.640715   28.288393  ...   27.185417   \n",
       "...                               ...         ...  ...         ...   \n",
       "2024-10-25 00:00:00+00:00  233.175714  231.504286  ...  232.117849   \n",
       "2024-10-28 00:00:00+00:00  233.354285  232.049285  ...  232.438385   \n",
       "2024-10-29 00:00:00+00:00  233.164285  232.344285  ...  232.746288   \n",
       "2024-10-30 00:00:00+00:00  232.252858  232.420000  ...  232.084718   \n",
       "2024-10-31 00:00:00+00:00  230.831430  232.302858  ...  230.541039   \n",
       "\n",
       "Price                           EMA25       EMA99      EMA200      MACD  \\\n",
       "Ticker                                                                    \n",
       "Date                                                                      \n",
       "2015-08-19 00:00:00+00:00   29.811806   30.819353   30.361521 -0.639367   \n",
       "2015-08-20 00:00:00+00:00   29.684936   30.766216   30.339640 -0.675706   \n",
       "2015-08-21 00:00:00+00:00   29.435326   30.679692   30.300837 -0.833884   \n",
       "2015-08-24 00:00:00+00:00   29.154147   30.581698   30.255854 -1.000959   \n",
       "2015-08-25 00:00:00+00:00   28.906520   30.488764   30.212860 -1.108087   \n",
       "...                               ...         ...         ...       ...   \n",
       "2024-10-25 00:00:00+00:00  229.678046  219.220789  207.361942  2.040117   \n",
       "2024-10-28 00:00:00+00:00  229.964350  219.504373  207.621027  2.033819   \n",
       "2024-10-29 00:00:00+00:00  230.249399  219.787685  207.880220  2.027246   \n",
       "2024-10-30 00:00:00+00:00  230.237908  219.993932  208.101313  1.714208   \n",
       "2024-10-31 00:00:00+00:00  229.904992  220.112253  208.278514  1.115170   \n",
       "\n",
       "Price                             CCI  Upper Band  Lower Band Ulcer Index  \\\n",
       "Ticker                                                                      \n",
       "Date                                                                        \n",
       "2015-08-19 00:00:00+00:00  -59.662038   30.115768   28.050661    8.949397   \n",
       "2015-08-20 00:00:00+00:00 -101.719165   29.807586   28.049914    8.822285   \n",
       "2015-08-21 00:00:00+00:00 -193.641185   30.187027   27.217616    8.940749   \n",
       "2015-08-24 00:00:00+00:00 -286.791374   30.611922   26.381293    9.012688   \n",
       "2015-08-25 00:00:00+00:00 -175.033141   30.766350   25.810436    9.087065   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-10-25 00:00:00+00:00   34.671127  237.405189  225.603382    1.664750   \n",
       "2024-10-28 00:00:00+00:00   76.852796  237.075664  227.022906    1.484857   \n",
       "2024-10-29 00:00:00+00:00   67.831787  237.229760  227.458811    1.465655   \n",
       "2024-10-30 00:00:00+00:00   13.082281  237.127918  227.712083    1.568988   \n",
       "2024-10-31 00:00:00+00:00  -82.148649  237.541362  227.064353    1.870281   \n",
       "\n",
       "Price                     Close Next Day  \n",
       "Ticker                                    \n",
       "Date                                      \n",
       "2015-08-19 00:00:00+00:00      28.162500  \n",
       "2015-08-20 00:00:00+00:00      26.440001  \n",
       "2015-08-21 00:00:00+00:00      25.780001  \n",
       "2015-08-24 00:00:00+00:00      25.934999  \n",
       "2015-08-25 00:00:00+00:00      27.422501  \n",
       "...                                  ...  \n",
       "2024-10-25 00:00:00+00:00     233.399994  \n",
       "2024-10-28 00:00:00+00:00     233.669998  \n",
       "2024-10-29 00:00:00+00:00     230.100006  \n",
       "2024-10-30 00:00:00+00:00     225.910004  \n",
       "2024-10-31 00:00:00+00:00     225.910004  \n",
       "\n",
       "[2317 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 161 ms (started: 2024-11-21 14:39:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def load_processed_data(data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Load processed DataFrames list and numpy arrays from files\n",
    "    \"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    # Load list of DataFrames\n",
    "    with open(data_path / 'processed_dfs.pkl', 'rb') as f:\n",
    "        processed_dfs = joblib.load(f)\n",
    "    \n",
    "    # Load numpy arrays\n",
    "    values_path = data_path / 'values_array.npy'\n",
    "    values_list = np.load(values_path, allow_pickle=True)\n",
    "    \n",
    "    return processed_dfs, values_list\n",
    "\n",
    "processed_dfs, values_list = load_processed_data('processed_data')\n",
    "processed_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad6ccf5-ec0c-4604-bd56-1d8aa11e6768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:58:00.875046Z",
     "iopub.status.busy": "2024-11-20T19:58:00.874890Z",
     "iopub.status.idle": "2024-11-20T19:58:00.967528Z",
     "shell.execute_reply": "2024-11-20T19:58:00.966979Z",
     "shell.execute_reply.started": "2024-11-20T19:58:00.875026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes: X=(34865, 14, 20), y=(34865, 5)\n",
      "Validation shapes: X=(8474, 14, 20), y=(8474, 5)\n",
      "Number of features: 20\n",
      "time: 83.5 ms (started: 2024-11-20 19:58:00 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_stock_data(values_list, n_steps_in=14, n_steps_out=5, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Preprocess multiple stock datasets for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        values_list: List of numpy arrays containing stock data with technical indicators\n",
    "        n_steps_in: Number of lookback days\n",
    "        n_steps_out: Number of prediction days\n",
    "        train_split: Train/validation split ratio\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_X, train_y, val_X, val_y, global_scaler)\n",
    "    \"\"\"\n",
    "    # 1. Global scaling across all stocks\n",
    "    global_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    combined_values = np.vstack(values_list)\n",
    "    scaled_combined = global_scaler.fit_transform(combined_values)\n",
    "    \n",
    "    # 2. Split back into individual stocks\n",
    "    scaled_values_list = []\n",
    "    start_idx = 0\n",
    "    for values in values_list:\n",
    "        scaled_values_list.append(scaled_combined[start_idx:start_idx + len(values)])\n",
    "        start_idx += len(values)\n",
    "    \n",
    "    # 3. Create sequences for each stock\n",
    "    train_X_list, train_y_list = [], []\n",
    "    val_X_list, val_y_list = [], []\n",
    "    \n",
    "    for scaled_values in scaled_values_list:\n",
    "        # Remove 'Close Next Day' from features (last column)\n",
    "        features = scaled_values[:, :-1]  # All columns except the last one\n",
    "        targets = scaled_values[:, -1]    # Only the last column\n",
    "        \n",
    "        # Split into train/validation\n",
    "        n_train = int(len(features) * train_split)\n",
    "        \n",
    "        # Ensure we have enough data for both training and validation\n",
    "        if n_train <= n_steps_in + n_steps_out:\n",
    "            print(f\"Warning: Stock with {len(features)} samples is too short for meaningful splitting\")\n",
    "            continue\n",
    "            \n",
    "        # Split features and targets\n",
    "        train_features = features[:n_train]\n",
    "        train_targets = targets[:n_train]\n",
    "        val_features = features[n_train:]\n",
    "        val_targets = targets[n_train:]\n",
    "        \n",
    "        # Create sequences\n",
    "        if len(train_features) > n_steps_in + n_steps_out:\n",
    "            train_X, train_y = create_sequences(train_features, train_targets, n_steps_in, n_steps_out)\n",
    "            train_X_list.append(train_X)\n",
    "            train_y_list.append(train_y)\n",
    "            \n",
    "        if len(val_features) > n_steps_in + n_steps_out:\n",
    "            val_X, val_y = create_sequences(val_features, val_targets, n_steps_in, n_steps_out)\n",
    "            val_X_list.append(val_X)\n",
    "            val_y_list.append(val_y)\n",
    "    \n",
    "    # 4. Combine all sequences\n",
    "    train_X = np.vstack(train_X_list)\n",
    "    train_y = np.vstack(train_y_list)\n",
    "    val_X = np.vstack(val_X_list)\n",
    "    val_y = np.vstack(val_y_list)\n",
    "    \n",
    "    print(f\"Training shapes: X={train_X.shape}, y={train_y.shape}\")\n",
    "    print(f\"Validation shapes: X={val_X.shape}, y={val_y.shape}\")\n",
    "    print(f\"Number of features: {train_X.shape[2]}\")\n",
    "    \n",
    "    return train_X, train_y, val_X, val_y, global_scaler\n",
    "\n",
    "def create_sequences(features, targets, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Generate synchronized sequences for LSTM input features and output targets.\n",
    "    \n",
    "    Args:\n",
    "        features: Scaled feature data (numpy array)\n",
    "        targets: Scaled target data (numpy array)\n",
    "        n_steps_in: Number of input time steps\n",
    "        n_steps_out: Number of output time steps\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X sequences, y sequences)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Ensure we have enough data for sequence creation\n",
    "    if len(features) < n_steps_in + n_steps_out:\n",
    "        raise ValueError(\"Data length is too short for the specified sequence lengths\")\n",
    "    \n",
    "    for i in range(len(features) - n_steps_in - n_steps_out + 1):\n",
    "        # Input sequence (n_steps_in days of all features)\n",
    "        seq_x = features[i:(i + n_steps_in)]\n",
    "        # Output sequence (next n_steps_out days of target variable)\n",
    "        seq_y = targets[(i + n_steps_in):(i + n_steps_in + n_steps_out)]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "train_X, train_y, val_X, val_y, scaler = preprocess_stock_data(values_list, n_steps_in, n_steps_out, train_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06a190-2384-43a7-a887-f2c49da964a8",
   "metadata": {},
   "source": [
    "# hypeparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b63ffd1-4f8c-49c4-93c9-98a3985189ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:58:01.237191Z",
     "iopub.status.busy": "2024-11-20T19:58:01.236986Z",
     "iopub.status.idle": "2024-11-20T19:58:01.787268Z",
     "shell.execute_reply": "2024-11-20T19:58:01.786838Z",
     "shell.execute_reply.started": "2024-11-20T19:58:01.237175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 160\n",
      "Best trial:\n",
      "  Value: 0.009632410481572151\n",
      "time: 545 ms (started: 2024-11-20 19:58:01 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# import optuna\n",
    "# from optuna import Trial\n",
    "# import plotly\n",
    "\n",
    "# # sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "\n",
    "# # Enable Optuna performance optimizations\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING) # Reduce logging overhead\n",
    "\n",
    "# # Define pruner to stop unpromising trials early\n",
    "# pruner = optuna.pruners.MedianPruner(\n",
    "#     n_startup_trials=5,\n",
    "#     n_warmup_steps=5,\n",
    "#     interval_steps=3\n",
    "# )\n",
    "\n",
    "# def objective(trial):\n",
    "#     tf.keras.backend.clear_session()\n",
    "    \n",
    "#     # Hyperparameters to tune\n",
    "#     n_layers = trial.suggest_int('n_layers', 1, 3)  # Number of LSTM layers\n",
    "#     units = trial.suggest_int('units', 25, 200, log=True)  # Number of units per LSTM layer\n",
    "#     dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "#     batch_size = trial.suggest_int('batch_size', 50, 64, log=True)\n",
    "\n",
    "#     # Create the LSTM model\n",
    "#     model = Sequential()\n",
    "#     for i in range(n_layers):\n",
    "#         return_sequences = i < n_layers - 1  # Return sequences for all layers except the last\n",
    "#         if i == 0:\n",
    "#             model.add(LSTM(units, activation='leaky_relu', dropout=dropout, \n",
    "#                            return_sequences=return_sequences,\n",
    "#                            input_shape=(train_X.shape[1], train_X.shape[2]),\n",
    "#                            name=f'lstm_layer_{i}'))\n",
    "#         else:\n",
    "#             model.add(LSTM(units, activation='leaky_relu', dropout=dropout, \n",
    "#                            return_sequences=return_sequences,\n",
    "#                            name=f'lstm_layer_{i}'))\n",
    "\n",
    "#     model.add(Dense(train_y.shape[1]))\n",
    "    \n",
    "#     # Compile the model\n",
    "#     early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)\n",
    "#     optimizer = Adam(learning_rate=1e-4)\n",
    "#     model.compile(optimizer=optimizer, loss='mae')\n",
    "    \n",
    "#     # Train the model\n",
    "#     history = model.fit(\n",
    "#         train_X, train_y,\n",
    "#         validation_data=(val_X, val_y),\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         verbose=0,\n",
    "#         shuffle=False,\n",
    "#         callbacks=[early_stopping]\n",
    "#     )\n",
    "    \n",
    "#     # Return the minimum validation loss\n",
    "#     return min(history.history['val_loss'])\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", storage=\"sqlite:///optuna.db\", study_name='lstm_model_3', load_if_exists=True)\n",
    "# # study.optimize(objective, n_trials=50, gc_after_trial=True, show_progress_bar=True)\n",
    "# print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: {}\".format(trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56beb63-ea35-41c8-9d6e-f53b6ee05f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:58:02.295553Z",
     "iopub.status.busy": "2024-11-20T19:58:02.295243Z",
     "iopub.status.idle": "2024-11-20T19:58:02.300064Z",
     "shell.execute_reply": "2024-11-20T19:58:02.299427Z",
     "shell.execute_reply.started": "2024-11-20T19:58:02.295526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.06 ms (started: 2024-11-20 19:58:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "import plotly\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "\n",
    "# Enable Optuna performance optimizations\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # Reduce logging overhead\n",
    "\n",
    "# Create a more efficient sampler\n",
    "sampler = optuna.samplers.TPESampler(\n",
    "    multivariate=True,  # Enable multivariate sampling\n",
    "    n_startup_trials=10,  # Reduce number of random trials\n",
    "    n_ei_candidates=24,  # Increase candidate points for expected improvement\n",
    ")\n",
    "\n",
    "# Define pruner to stop unpromising trials early\n",
    "pruner = optuna.pruners.MedianPruner(\n",
    "    n_startup_trials=5,\n",
    "    n_warmup_steps=5,\n",
    "    interval_steps=3\n",
    ")\n",
    "\n",
    "def objective(trial):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Hyperparameters to tune\n",
    "    # n_layers = trial.suggest_int('n_layers', 1, 3)  # Number of LSTM layers\n",
    "    units = trial.suggest_int('units', 25, 100, log=True)  # Number of units per LSTM layer\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'leaky_relu', 'gelu']) \n",
    "    # batch_size = trial.suggest_int('batch_size', 16, 64, log=True)\n",
    "\n",
    "    # Create the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, activation=activation, dropout=dropout, \n",
    "                           return_sequences=False,\n",
    "                           input_shape=(train_X.shape[1], train_X.shape[2]),\n",
    "                           name=f'lstm_layer_1'))\n",
    "\n",
    "    model.add(Dense(train_y.shape[1]))\n",
    "    \n",
    "    # Compile the model\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='min', restore_best_weights=True)\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss='mae')\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_X, train_y,\n",
    "        validation_data=(val_X, val_y),\n",
    "        epochs=epochs,\n",
    "        batch_size=64,\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    # Return the minimum validation loss\n",
    "    return min(history.history['val_loss'])\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", \n",
    "                                storage=\"sqlite:///optuna.db\", \n",
    "                                study_name='lstm_model_4', \n",
    "                                load_if_exists=True)\n",
    "# study.optimize(objective, n_trials=50, gc_after_trial=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086cc3e-82d4-4fa7-9116-4c2a0598bef2",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84421eaf-7f87-4409-b27d-1bafd23e1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(n_steps_in, n_features, n_steps_out):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = Sequential([\n",
    "        LSTM(25, activation='leaky_relu', dropout=0.025, input_shape=(n_steps_in, n_features)),\n",
    "        Dense(n_steps_out)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    loss = ['mae']\n",
    "    model.compile(optimizer=optimizer, loss_weights=[1], loss=loss)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and train model\n",
    "model = create_lstm_model(n_steps_in=n_steps_in, n_features=train_X.shape[2], n_steps_out=n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a2135-96f3-404e-9999-b0bdf0a115cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    validation_data=(val_X, val_y),\n",
    "    epochs=epochs,\n",
    "    batch_size=55,\n",
    "    verbose=2,\n",
    "    shuffle=False,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d04f6-671d-4141-b5ba-665bfd8beced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(val_X)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Evaluate for each time step\n",
    "for i in range(n_steps_out):\n",
    "    mse = mean_squared_error(val_y[:, i], y_pred[:, i])\n",
    "    print(f\"MSE for step {i+1}: {mse: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ad5cb-e6c5-4280-9ebf-973de0ac3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_y[0], label='True')\n",
    "plt.plot(y_pred[0], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('True vs Predicted - Multi-step Forecasting')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862aae5-be4d-4c25-bf13-c4aeb4018146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig1, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Loss plot\n",
    "N = len(history.history[\"loss\"])\n",
    "epoch_range = np.arange(0, N)\n",
    "\n",
    "ax1.plot(epoch_range, history.history[\"loss\"], label='Train MSE loss', marker='o', color='blue')\n",
    "ax1.plot(epoch_range, history.history[\"val_loss\"], label='Validation MSE loss', marker='o', color='orange')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('MAE Loss', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "ax1.set_title('MAE Loss During Training')\n",
    "\n",
    "# RMSE plot (shared x-axis, different y-axis)\n",
    "# ax2 = ax1.twinx()\n",
    "# fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
    "# ax2.plot(epoch_range, history.history[\"unscaled_mse\"], label='Train MSE', color='green')\n",
    "# ax2.plot(epoch_range, history.history[\"val_unscaled_mse\"], label='Validation MSE', color='red')\n",
    "# ax2.set_xlabel('Epochs')\n",
    "# ax2.set_ylabel('Root Mean Squared Error (RMSE)', color='green')\n",
    "# ax2.tick_params(axis='y', labelcolor='green')\n",
    "# ax2.legend(loc='upper left')\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# ax2.set_title('RMSE During Training')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f34b6c-6ed8-453c-83d1-dcb58a4131f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
